{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic numpy manipulation\n",
    "\n",
    "Write two ways to get the diagonal elements of a dot product of two matrices, A and B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.arange(25).reshape(5,5)\n",
    "B = np.arange(25).reshape(5,5)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.diag(np.dot(A, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A * B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.sum(A * B.T, axis=1)  # what does this do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given some matrix (row normalized to 1.0):\n",
    "\n",
    "```python\n",
    " P = [[ 0.30434783  0.34782609  0.34782609]\n",
    "     [ 0.08333333  0.25        0.66666667]\n",
    "     [ 0.75        0.16666667  0.08333333]]\n",
    " ```\n",
    "\n",
    "Find the stationary distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P = np.array([[ 0.30434783, 0.34782609, 0.34782609],[0.08333333,  0.25, 0.66666667], [ 0.75, 0.16666667,  0.08333333]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "2^5\n",
    "2*2*2*2*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def raise_nth_power(n, transition):\n",
    "    ''' Solve for stationary distribution by raising to the nth power '''\n",
    "    \n",
    "    temp = transition\n",
    "    for i in np.arange(n-1):    \n",
    "        temp = transition.dot(temp)\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 50\n",
    "print raise_nth_power(n,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# how to run a linear regression using scikit learn. See week 3 notebook for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 4 - Strings\n",
    "====\n",
    "\n",
    "<ul>\n",
    "<li>Text analysis is a *huge* part of data analysis - its not just numbers\n",
    "<li>Need to standardize variables, resolve ambiguous labels\n",
    "<li>Converting text to numeric representations (word bagging, n-grams) is common\n",
    "</ul>\n",
    "\n",
    "## Today\n",
    "\n",
    "1. [Tweet example](#tweet)\n",
    "2. [string modules](#modules)\n",
    "<ol>\n",
    "<li>os\n",
    "<li>collections\n",
    "</ol>\n",
    "3. [Regular Expressions](#regex)\n",
    "4. [Review Problems](#hmwk)\n",
    "\n",
    "### And if there is time - either more Regression or intro Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis on Obama's tweets<a id=\"tweet\"></a>\n",
    "====\n",
    "\n",
    "<ul>\n",
    "<li>One of Python’s strengths is the ease of working with text\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib     # popular module for fetching data from web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = ['positive.txt','obama_tweets.txt']     # create list of filenames\n",
    "path = 'http://www.unc.edu/~ncaren/haphazard/'   # this URL has good text documents to practice on\n",
    "\n",
    "for file_name in files:\n",
    "     urllib.urlretrieve(path + file_name,file_name)    # pull down text data from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_file = open(\"obama_tweets.txt\").read()\n",
    "tweet_file[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can we get a handle on all this text?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String methods\n",
    "\n",
    "<ul>\n",
    "<li>`Split` a string according to some character. This creates a list of strings out of the original string.\n",
    "<li>`Join` a list of strings together according to some delimiter     \n",
    "<li>`Strip` leading and trailing blanks around a word  \n",
    "<li>`count` the number of exact matches\n",
    "<li>`find` the index of first occurrence. `-1` if doesn't exist\n",
    "<li>`replace` replaces every occurrence of one pattern with another\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = tweet_file.split('\\n')   # very commonly used\n",
    "tweets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(tweets)\n",
    "tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "# Average number of hashtags total?\n",
    "# I hope you remember your list comprehensions :)\n",
    "\n",
    "sum([tweet.count('#') for tweet in tweets])/len(tweets)      # exact matching pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print tweets[300]\n",
    "print tweets[300].find('a')  # only first occurrence\n",
    "print tweets[300].find('!')  # -1 if doesn't occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of tweets with no #?\n",
    "\n",
    "sum([tweet.find('#') == -1  for tweet in tweets])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets[300].replace('Obama', \"Trump\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic string manipulation - example\n",
    "\n",
    "Pull out the `methods` from the markdown text below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "objective = \"Basic string manipulation\"\n",
    "\n",
    "<ul>\n",
    "  <li>`Split` a string according to some character. This creates a list of strings out of the original string.\n",
    "  <li>`Join` a list of strings together according to some delimiter     \n",
    "  <li>`Strip` leading and trailing blanks around a word  \n",
    "  <li>`count` the number of exact matches\n",
    "  <li>`find` the index of first occurrence. `-1` if doesn't exist\n",
    "  <li>`replace` replaces every occurrence of one pattern with another\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "objective = \"Basic string manipulation\"\n",
    "\n",
    "s = \"\"\"\n",
    "<ul>\n",
    "  <li>`Split` a string according to some character. This creates a list of strings out of the original string.\n",
    "  <li>`Join` a list of strings together according to some delimiter     \n",
    "  <li>`Strip` leading and trailing blanks around a word  \n",
    "  <li>`count` the number of exact matches\n",
    "  <li>`find` the index of first occurrence. `-1` if doesn't exist\n",
    "  <li>`replace` replaces every occurrence of one pattern with another\n",
    "</ul>\n",
    "\"\"\"\n",
    "s     # where's the newline characters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_list = [i for i in s.split('\\n')]\n",
    "split_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_list[2:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strip_list = [i.strip('   <li>') for i in split_list[2:-2]] # remove trailing space and markdown characters\n",
    "strip_list\n",
    "\n",
    "# should remove first two and last two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenize = [i.split(' ') for i in strip_list]\n",
    "print tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_words = [i[0].strip('`') for i in tokenize]\n",
    "final_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\" + \".join(final_words) + \" = {}\".format(objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE TIME!\n",
    "\n",
    "Format your `PATH` variable such that it looks like this:\n",
    "\n",
    "```\n",
    "=> bin=> sh\n",
    "=> Users=> ilanman=> sparkapphelper=> scala-2.11.7=> bin=> bin\n",
    "=> Users=> ilanman=> sparkapphelper=> spark=> spark-1.6.0-bin-hadoop2.6=> bin\n",
    "=> Users=> ilanman=> sparkapphelper=> sbt=> sbt-0.13.11=> bin\n",
    "=> Library=> Java=> JavaVirtualMachines=> jdk1.8.0_60.jdk=> Contents=> Home=> bin\n",
    "=> usr=> local=> bin\n",
    "=> usr=> bin\n",
    "=> bin\n",
    "=> usr=> sbin\n",
    "=> sbin\n",
    "=> opt=> X11=> bin\n",
    "=> Library=> TeX=> texbin\n",
    "No such file or directory\n",
    "```\n",
    "\n",
    "Note that Jupyter can access your terminal by entering `!` before regular terminal commands, i.e. `!mkdir newfolder`<br>\n",
    "\n",
    "Here is my current `PATH`: `!echo $PATH`\n",
    "\n",
    "`/Users/ilanman/spark/bin:/Users/ilanman/sbt/bin:/Library/Java/JavaVirtualMachines/jdk1.8.0_60.jdk/Contents/Home/bin`<br>\n",
    "`/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin:/Library/TeX/texbin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paths = !`echo $PATH`\n",
    "print paths     # paths is a list of strings\n",
    "print len(paths)\n",
    "path_strings = paths[0]\n",
    "print path_strings\n",
    "all_paths = path_strings.split(':')  # split on : which is what separates paths\n",
    "print all_paths\n",
    "for path in all_paths:\n",
    "    print '=> '.join(path.strip().split('/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess positive or negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_file = open(\"positive.txt\").read()\n",
    "positive_file[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_file.split('\\n')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's the positive sentiment in the tweets?\n",
    "\n",
    "<ul>\n",
    "<li>Iterate through tweets and count occurrence of positive words. \n",
    "<li>Need to do a bit a cleaning first.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The punctuation function is useful for getting rid of unwanted characters in a string\n",
    "from string import punctuation\n",
    "print punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## os module\n",
    "\n",
    "<ul>\n",
    "<li>`os` module provides a way of using operating system dependent functionality. You can find important information about your location or about the process.\n",
    "<li>We'll look at this in more detail next session\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Alice in Wonderland from Project Gutenberg\n",
    "\n",
    "if not os.path.exists('alice.txt'):\n",
    "    ! curl http://www.gutenberg.org/cache/epub/11/pg11.txt -O alice.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head -50 pg11.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collections modules\n",
    "\n",
    "<ul>\n",
    "<li>Very useful module for text manipulation, analysis. Lots of iterating over dictionary-like objects.\n",
    "<li>`OrderedDict`\n",
    "<li>`defaultdict`\n",
    "<li>`namedtuple`\n",
    "<li>`Counter`\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alice = open('pg11.txt').read()  # read in file\n",
    "\n",
    "# split words on spaces, remove punctuation and make lower case\n",
    "words = alice.translate(None, punctuation).lower().split()    # common to chain together string methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(words)\n",
    "print len(set(words))   # set - unique elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digression on Sets\n",
    "\n",
    "<ul>\n",
    "<li>Another python data type\n",
    "<li>Can use `{some_sequence}` or `set(some_list)` to create it\n",
    "<li>Like lists or tuples, but returns **unique** elements. This can be super handy.\n",
    "<li>Has a specific way of thinking about it\n",
    "<li>`add`, `intersection`, `union`\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = [1,2,3,2,1,2,3,4,5,6,7,6,5,4,3,3]  # some list\n",
    "set(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = {1,2,3,2,1,2,3,4,5,6,7,6,5,4,3,3}\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(['this is a sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set('this is a sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5]\n",
    "b = [3,4,5,6,7]\n",
    "set(a).intersection(set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(a).union(set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(b).difference(set(a))   # a - b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to find 10 most common words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_common = {}\n",
    "\n",
    "# use set to find unique words, store in dictionary\n",
    "for word in set(words):\n",
    "    most_common.update({word : words.count(word)})     # WHAT DOES UPDATE DO?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To find top 10, need to sort dictionary on values. There are <em>MANY</em> ways to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_common.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using base python\n",
    "\n",
    "sorted_words_lambda = sorted(most_common.items(), key = lambda x: x[1], reverse = True)\n",
    "sorted_words_lambda[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using itemgetter from operator module\n",
    "from operator import itemgetter\n",
    "\n",
    "sorted_words_itemgetter = sorted(most_common.items(), key = itemgetter(1), reverse = True)\n",
    "sorted_words_itemgetter[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# using collections module\n",
    "from collections import OrderedDict\n",
    "\n",
    "sorted_words_collections = OrderedDict(sorted(most_common.items(), key = lambda x: x[1], reverse = True))\n",
    "sorted_words_collections.items()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# default dict\n",
    "\n",
    "from collections import defaultdict\n",
    "inverse = defaultdict( list )\n",
    "\n",
    "for k, v in most_common.items():\n",
    "    inverse[v].append( k )\n",
    "\n",
    "for k in sorted(inverse,reverse=True)[:10]:\n",
    "    print inverse[k][0], k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# named tuple\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "sorted_words_named = namedtuple('word', 'word count')\n",
    "sorted_words_named = sorted([sorted_words_named(v,k) for (k,v) in most_common.items()], reverse=True)\n",
    "sorted_words_named[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using Counter\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "sorted_words_counter = [item for item in Counter(words).most_common(10)]\n",
    "sorted_words_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE TIME!\n",
    "\n",
    "Find the number of words that appear exactly 10 times in the book. Use a python module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## SOLUTION\n",
    "\n",
    "alice_counter = Counter(alice.split())\n",
    "len([(k, v) for (k, v) in alice_counter.items() if v==10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find positive sentiment from tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Helpful to standardize tweets\n",
    "<li>Convert to lower case\n",
    "<li>Remove punctuation\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_word_dict = {}\n",
    "\n",
    "positives = positive_file.split('\\n')[::-1][1:]\n",
    "\n",
    "for tweet in tweets:   # for all tweets\n",
    "    for positive_word in positives:   # for all positive words\n",
    "        if positive_word in tweet.translate(None, punctuation).lower():   # if positive word in tweet\n",
    "            positive_word_dict[positive_word] = positive_word_dict.get(positive_word, 0)  # WHAT DOES GET DO?\n",
    "            positive_word_dict[positive_word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(positive_word_dict.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the most common positive word used in the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[item for item in Counter(positive_word_dict).most_common(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE TIME!\n",
    "\n",
    "Do a similar analysis above but using negative words. \n",
    "\n",
    "1) Read in the `negative.txt` file and store it in a variable call it `negative`.<br>\n",
    "2) Using `negative`, find the 10 most common negative words in the tweets. Comment on any interesting observations.<br>\n",
    "3) For the most common negative word, print 10 tweets that contain it. Comment on any interesting observations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## SOLUTION\n",
    "\n",
    "negative = open(\"negative.txt\").read()\n",
    "negative_word_dict = {}\n",
    "\n",
    "for tweet in tweets:\n",
    "    for negative_word in negative.split('\\n')[::-1][1:]:\n",
    "        if negative_word in tweet.translate(None, punctuation).lower():\n",
    "            negative_word_dict[negative_word] = negative_word_dict.get(negative_word, 0)\n",
    "            negative_word_dict[negative_word] += 1\n",
    "\n",
    "negative_counts = [item for item in Counter(negative_word_dict).most_common(10)]\n",
    "print negative_counts\n",
    "\n",
    "counter = 0\n",
    "for tweet in tweets:\n",
    "    if negative_counts[0][0] in tweet.translate(None, punctuation).lower():\n",
    "        counter += 1\n",
    "        if counter <= 10:\n",
    "            print tweet\n",
    "            print 80*'-'\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happened??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Expression <a id=\"regex\"></a>\n",
    "-----\n",
    "\n",
    "<ul>\n",
    "<li>Special sequence of characters that helps you match (**exact!**) or find other strings or sets of strings, using a specialized syntax held in a pattern\n",
    "<li>Regular expressions as a concept is not exclusive to Python at all.\n",
    "<li>Regular expressions are widely used in UNIX world.\n",
    "<li>`re` module\n",
    "        <ul>\n",
    "        <li>`re.compile()`\n",
    "        <li>`re.match()`\n",
    "        <li>`re.search()`\n",
    "        <li>`re.findall()`\n",
    "        <li>`re.sub()`\n",
    "        </ul>\n",
    "<li>In python, regular expressions tend to be **very slow**. So only use if necessary.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from re import match, search, findall, compile, sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# python treats / as an escape character. So \"/n\" is a newline object, not a literal '/n'\n",
    "# to de-pythonify a string, add r' to the front - this makes it a raw string\n",
    "\n",
    "string = 'This is a\\nnormal string with a newline and \\ttab character'\n",
    "rawString = r'and this is a\\nraw string which can be used to search for \\tpatterns'\n",
    "print string\n",
    "print \"+++++++++++++++++\"\n",
    "print rawString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `match` - only find matches if they occur at the start of the string being searched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_string = \"I'm learning about regular expressions and about how to use them in Python. This is fantastic stuff!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match_pattern = match(\"I'm\", test_string) # return pattern matched by query\n",
    "print match_pattern\n",
    "print match_pattern.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print match(\"about\", test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### `search` - similar to `match`, but `search` doesn’t restrict us to only finding matches at the beginning of the string. But will only return the first result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_pattern = search('about', test_string)\n",
    "print search_pattern\n",
    "search_pattern.group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### `findall` - get a list of all matching patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "findall('about',test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "findall('an',test_string)  # no good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "findall(' an ',test_string)  # kinda hacky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word = 'about'\n",
    "findall(r'\\b' + word + r'\\b', test_string)  # better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word = 'about'\n",
    "test_string.count(word)  # count() is ok for simple searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `compile` to create regular expressions that you can then `search`, `findall`, `match`, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word = 'about'\n",
    "expr = compile(r'\\b' + word + r'\\b')  # can get complex\n",
    "print findall(expr, test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE TIME!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redo the negative tweet exercise from above to perform exact matching. That is:<br>\n",
    "\n",
    "1) Using negative, find the 10 most common negative words in the tweets. Comment on any interesting observations.<br>\n",
    "2) For the most common negative word, print 10 tweets that contain it. Comment on any interesting observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## SOLUTION\n",
    "\n",
    "negative = open(\"negative.txt\").read()\n",
    "negative_word_dict = {}\n",
    "\n",
    "for tweet in tweets:\n",
    "    for negative_word in negative.split('\\n')[::-1][1:]:  # Since the last item is a ' ', reverse the list and skip it\n",
    "     \n",
    "    #    Note that you could also use count() - this is much faster\n",
    "        num_occurence = tweet.translate(None, punctuation).lower().count(' ' + negative_word + ' ')\n",
    "    \n",
    "        # Unlike the previos exercise - here we increment the dictionary by the number of occurences, \n",
    "        # not just 1 for each occurence\n",
    "    #    num_occurence = len(findall(r'\\b' + negative_word + r'\\b', tweet.translate(None, punctuation).lower()))\n",
    "        \n",
    "        if num_occurence > 0:\n",
    "            negative_word_dict[negative_word] = negative_word_dict.get(negative_word, 0)\n",
    "            negative_word_dict[negative_word] += num_occurence\n",
    "\n",
    "most_negative = [item for item in Counter(negative_word_dict).most_common(10)]\n",
    "print most_negative\n",
    "\n",
    "counter = 0\n",
    "# store most negative word as a regular expression\n",
    "regex = compile(r'\\s' + most_negative[0][0] + '\\s')\n",
    "\n",
    "for tweet in tweets:\n",
    "    # search returns a true or false\n",
    "    if search(regex, tweet.translate(None, punctuation).lower()):\n",
    "        counter += 1\n",
    "        if counter <= 10:\n",
    "            print tweet\n",
    "            print 80*'-'   # add dashed line for easier reading\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the distribution of negative word occurrence?\n",
    "\n",
    "**Let's plot it!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "common_words = Counter(positive_word_dict).most_common(40)\n",
    "common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ys = [i[1] for i in common_words]   # number of occurrences\n",
    "xs = [i[0] for i in common_words]   # words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))  # set the canvas size\n",
    "plt.plot(ys, linewidth = 2)    # call a line plt\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns   # let's use seaborn in our plotting environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))  # set the canvas size\n",
    "plt.plot(ys, linewidth = 2)    # call a line plt\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is this chart helpful?\n",
    "\n",
    "Where are the words??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))  # set the canvas size\n",
    "plt.plot(ys, linewidth = 2)    # call a line plt\n",
    "plt.xticks(range(len(xs)), xs, rotation = 40)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word_length_dict = {}\n",
    "for tweet in tweets:\n",
    "    for word in filter(None,tweet.translate(None, punctuation).split(' ')):\n",
    "        word_length_dict[len(word)] = word_length_dict.get(len(word),0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_length_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ys = [v for k, v in word_length_dict.items()]\n",
    "xs = [k for k, v in word_length_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "plt.plot(ys, linewidth=2)\n",
    "plt.xticks(range(len(xs)), xs,rotation=35)\n",
    "plt.title(\"Distribution of word length\",size=16)\n",
    "plt.ylabel(\"Frequency\",size=14)\n",
    "plt.xlabel(\"Word length\",size=14)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anyone notice something strange about the chart?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(max(word_length_dict.keys())):\n",
    "    if i not in word_length_dict.keys():\n",
    "        word_length_dict[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_length_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys = [v for k, v in word_length_dict.items()]\n",
    "xs = [k for k, v in word_length_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "plt.plot(ys,linewidth=2)\n",
    "plt.xticks(range(len(xs)), xs,rotation=35)\n",
    "plt.title(\"Distribution of word length\",size=16)\n",
    "plt.ylabel(\"Frequency\",size=14)\n",
    "plt.xlabel(\"Word length\",size=14)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-grams\n",
    "\n",
    "<ul>\n",
    "<li>Single word counts is ok, but for richer text analysis might want combinations of words\n",
    "<li>bi-grams, tri-grams, ..., n-grams\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# example of bi grams of first tweet\n",
    "\n",
    "tweet = tweets[0].split(' ')\n",
    "bigrams = []\n",
    "\n",
    "for i in range(len(tweet)-1): # need to stop 1 element before the end\n",
    "    bigrams.append((tweet[i], tweet[i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# example of trigrams of first tweet\n",
    "\n",
    "tweet = tweets[0].split(' ')\n",
    "trigrams = []\n",
    "\n",
    "for i in range(len(tweet)-2):\n",
    "    trigrams.append((tweet[i], tweet[i+1], tweet[i+2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE TIME\n",
    "\n",
    "1. Write your own bigram function. Do this without using a for loop. Hint - look up the `zip` function.\n",
    "2. Do the same for tri grams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## SOLUTION\n",
    "\n",
    "\n",
    "def bigrams(twt):\n",
    "    return zip(twt, twt[1:])\n",
    "\n",
    "print bigrams(tweet)\n",
    "print\n",
    "\n",
    "def trigrams(twt):\n",
    "    return zip(twt, twt[1:], twt[2:])\n",
    "\n",
    "print trigrams(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take Away\n",
    "\n",
    "<ul>\n",
    "<li>Manipulating strings and text analysis\n",
    "<li>Reading files from the web and local \n",
    "<li>Basic plotting\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review Problems<a id=\"hmwk\"></a>\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1**.\n",
    "\n",
    "Write a function to remove vowels from a string. Stick to base python only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## SOLUTION\n",
    "\n",
    "def remove_vowels(s):\n",
    "    vowels = \"aeiouAEIOU\"\n",
    "    s_without_vowels = \"\"\n",
    "    for letter in s:\n",
    "        if letter not in vowels:\n",
    "            s_without_vowels += letter\n",
    "    return s_without_vowels\n",
    "\n",
    "remove_vowels('This sentence has no vowels. Cray cray!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. \n",
    "For the next few questions, read in `Through the Looking glass` from Project Gutenberg (`pg12.txt`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('alice.txt'):\n",
    "    ! curl http://www.gutenberg.org/cache/epub/12/pg12.txt -O alice.txt        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poem = open('pg12.txt').read()  # read in file\n",
    "print poem[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A)**. Print the subset starting from `'JABBERWOCKY'` and ending with `'It seems very pretty.'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = poem.find('JABBERWOCKY')\n",
    "end = poem.find('It seems very pretty', start, end)\n",
    "poem = poem[start:end - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B)**. Print all *distinct* palindromic words, if any. Remember to 'standardize' first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## SOLUTION\n",
    "\n",
    "import string\n",
    "poem = poem.lower()\n",
    "poem = poem.translate(None, string.punctuation)\n",
    "words = poem.split()\n",
    "\n",
    "def is_palindrome(word):\n",
    "    return word == word[::-1] \n",
    "\n",
    "print set(word for word in words if is_palindrome(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C)**. Find all possible sequences of 3 words in the poem. This is called a trigram. (Hint: use `zip` or `islice` from `itertools`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## SOLUTION 1\n",
    "list(zip(words[:-2], words[1:-1], words[2:]))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## SOLUTION 2\n",
    "import itertools\n",
    "\n",
    "def window(x, n):\n",
    "    \"\"\"Sliding widnow of size n from iterable x.\"\"\"\n",
    "    s = (itertools.islice(x, i, None) for i in range(n))\n",
    "    return zip(*s)\n",
    "\n",
    "list(window(words, 3))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3**.\n",
    "\n",
    "Plot a similar distribution for the positive word count. The differences are:\n",
    "\n",
    "<ul>\n",
    "<li>Plot top 30 positive words only\n",
    "<li>Change the figure size\n",
    "<li>Change the rotation of the xticks\n",
    "<li>Change the linewidth and color\n",
    "</ul>\n",
    "\n",
    "Feel free to use the existing code as a template.<br>\n",
    "\n",
    "As an extra challenge, instead of plotting the count of each positive word in ascending order, plot the cumulative count of the positive words, as a % of the total count of positive words, for the first 30. Your chart should look something like this:\n",
    "\n",
    "<img id=\"cumulative\" src=\"../images/cumulative.png\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## SOLUTION\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(positive_word_dict,orient = 'index')\n",
    "df.columns = ['num']\n",
    "df.sort_values(by = ['num'], inplace = True, ascending = False)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(df.num.values[:30],linewidth=3,color='red')\n",
    "plt.xticks(range(len(df.index.values))[:30], df.index.values[:30],rotation=35)\n",
    "plt.title(\"Top 30 positive word occurrence\",size=16)\n",
    "plt.ylabel(\"Frequency\",size=14)\n",
    "plt.xlabel(\"Positive words\",size=14)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(positive_word_dict,orient = 'index')\n",
    "df.columns = ['num']\n",
    "df.sort_values(by = ['num'], inplace = True, ascending = False)\n",
    "\n",
    "df['cumulative_proportion'] = np.cumsum(df.num).values/sum(df.num.values)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(df['cumulative_proportion'].values[:30],linewidth=3,color='red')\n",
    "plt.xticks(range(len(df.index.values))[:30], df.index.values[:30],rotation=35)\n",
    "plt.title(\"Top 30 positive word occurrence\",size=16)\n",
    "plt.ylabel(\"Frequency\",size=14)\n",
    "plt.xlabel(\"Positive words\",size=14)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS QUESTION!\n",
    "\n",
    "**Q1**. Encode and decode `Through the Looking Glass` using a [Caesar cipher](https://en.wikipedia.org/wiki/Caesar_cipher) <br>\n",
    "\n",
    "Hint: create a function `encode(poem, shift)` where `shift` is the number of characters used to encode the cipher. It should return the encoded poem. Can you also use this function to return the decoded cipher? Check out the `maketrans` function in `string`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## SOLUTION\n",
    "import string\n",
    "\n",
    "def encode(poem, shift):\n",
    "    \n",
    "    shifted_alphabet = string.ascii_lowercase[shift:] + string.ascii_lowercase[:shift]\n",
    "    table = string.maketrans(string.ascii_lowercase, shifted_alphabet)\n",
    "    \n",
    "    return poem.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encode\n",
    "\n",
    "cipher = encode(poem, 2)\n",
    "print(cipher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Decode\n",
    "\n",
    "recovered = encode(cipher, -2)\n",
    "print(recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
